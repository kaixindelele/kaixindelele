### Hi there is kaixindelele 👋
寻求一份LLM相关的大厂工作，最近在更新简历



<!--
**kaixindelele/kaixindelele** is a ✨ _special_ ✨ repository because its `README.md` (this file) appears on your GitHub profile.

Here are some ideas to get you started:

- 🔭 I’m currently working on ...
- 🌱 I’m currently learning ...
- 👯 I’m looking to collaborate on ...
- 🤔 I’m looking for help with ...
- 💬 Ask me about ...
- 📫 How to reach me: ...
- 😄 Pronouns: ...
- ⚡ Fun fact: ...
-->





# Yongle Luo
电子邮箱：lyl1994@mail.ustc.edu.cn  
作品链接：[Github](https://github.com/DRLib) (10500+ stars)  
博客链接：[知乎：强化学徒](https://www.zhihu.com/people/heda-he-28) (5K 关注)  

## 求职意向

RLHF，基于LLM的具身智能或者LLM+论文辅助工具

## 教育经历

**郑州大学** | 自动化 | 本科 | 2013-2017  

**中国科学技术大学** | 模式识别与智能系统 | 研二转博；博士四年级在读 | 2017-至今  

## 研究经历

### 深度强化学习代码库DRLib
- 基于Spinning UP封装的深度强化学习算法：DQN、DDPG、TD3、SAC、PPO、PER、HER等。
- 深度强化学习算法链接：[DRLib](https://github.com/DRLib) (369 stars)

### 稀疏奖励矫正密集奖励的强化学习
- 论文综合稀疏奖励全局收敛但效率低下以及密集奖励收敛快但容易局部最优的特点，提出dense2sparse解决方案，兼顾二者的优势，同时提高探索效率和最终性能。
- 《Balance Between Efficient and Effective Learning: Dense2Sparse Reward Shaping for Robot Manipulation with Environment Uncertainty》（共一，机器人会议 2022 AIM，Oral Presentation）
- 23年改进版《D2SR: Transferring Dense Reward Function to Sparse by Network Resetting》，彻底解决稳定性的问题，性能大幅提升（一作，机器人EI会议RCAR，本月底，出结果）

### 乒乓球仿真搭建和真机验证—深度强化学习的单步决策高效学习
- 基于Mujoco物理引擎的乒乓球击球平台（唯一一个基于Mujoco的乒乓球环境），实现与真机类似的击球效果。
- 《SIRL: Self-Imitation Reinforcement Learning for Single-step Hitting Tasks》（一作，机器人会议ARM，同上）

### 自我引导持续强化学习—彻底解决深度强化学习，在稀疏奖励下复杂序列任务中效率低下的问题
- 首次提出自我引导探索的强化学习框架。面对奖励反馈稀疏的复杂任务，该算法可以让智能体从失败中提取有效信息，积极探索，不断积累优势，最终实现高效学习。在一到三物体的各类操作任务中都取得极高探索效率，真机实验从零开始训练仅需250回合即可达100%成功率，是本人博士期间最有学术价值的工作。
- 在此基础上的另外一个侧重于策略优化的工作正在撰写，可以使得样本效率再次提高60%以上。
- 代码已开源：[RHER](https://github.com/RHER); 论文已在ArXiv公布：[Relay Hindsight Experience Replay](https://arxiv.org/abs/xxxx.xxxx)（一作，NeuroComputing刚拿到大修结果）

## 证书及项目经历
- 证书：英语四六级、心理咨询师三级
- 项目经历：
  - 基于强化学习的竞技型乒乓球机器人运动控制系统研发（横向，148w，本人负责 仿真系统搭建和强化算法）
  - 开源ChatPaper，获得10K star，GitHub连续三天热榜第五，正在商业化，并在推动ChatOpenReview

## 自我评价
- 熟练掌握经典深度强化学习算法，拥有丰富的机器人仿真和真实系统搭建经验，7成几率秋季毕业，3成几率明年毕业。
- 品行良好，为人坦率靠谱。工程能力强，编程基础扎实。擅长将人类学习经验应用于人工智能领域，科研能力优秀，拥有丰富的团队合作经验，热爱开源、技术分享和教学。
- 对于目前的强化发展预估是，简单基于MLP的强化学习已经结束，下一步必须融入LLM，而LLM/LMM的世界模型，是机器人落地的基础，才能满足实际生产需求 。
- 个人对ChatPaper系列的规划，是希望能做一个垂直领域，为科研工作者加速，并且整个项目适合商业化运营。
-	希望能有一个机会，加入这次LLM的发展浪潮中。
